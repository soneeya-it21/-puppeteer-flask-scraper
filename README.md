ğŸ§  Puppeteer-Flask Scraper (Multi-Stage Docker Build)

A compact, containerized web scraping solution built using **Node.js with Puppeteer** for dynamic content extraction and **Python Flask** for lightweight hosting of scraped data. Designed as a multi-stage Docker application to demonstrate practical DevOps skills.

ğŸ”§ What It Does

- Uses **Puppeteer + Chromium** to headlessly browse and scrape a user-defined webpage.
- Extracts meaningful data such as the **page title** and **first heading**.
- Outputs the data into a JSON file.
- Uses a **Python Flask** web server to host the JSON as an API endpoint.
- Packaged into a **slim Docker container** using a multi-stage build to keep the final image lightweight.

ğŸš€ Deployment Highlights

âœ… Entire project was deployed and executed on an **AWS EC2 Ubuntu instance**  
âœ… Instance was accessed using **MobaXterm SSH client**  
âœ… Manual setup, code development, testing, Dockerization, and Git operations were all done remotely  
âœ… Final app scrapes **[TechCrunch â€“ Startup News](https://techcrunch.com/startups/)** and serves the result at `http://<your-ec2-public-ip>:5000/`


ğŸ“ Project Structure

puppeteer-flask-scraper/ 
â”œâ”€â”€ scraper/ 
â”‚ â”œâ”€â”€ scrape.js # Puppeteer scraping logic 
â”‚ â”œâ”€â”€ package.json # Node.js dependencies 
â”œâ”€â”€ server.py # Flask web server 
â”œâ”€â”€ requirements.txt # Python dependencies 
â”œâ”€â”€ Dockerfile # Multi-stage build 
â””â”€â”€ README.md # Project documentation


ğŸ³ Docker Multi-Stage Build

The `Dockerfile` consists of two stages:

1ï¸âƒ£ **Scraper Stage** (Node.js)
- Uses `node:18-slim`
- Installs Chromium & Puppeteer
- Runs `scrape.js` to fetch data and write to `scraped_data.json`

2ï¸âƒ£ **Hosting Stage** (Python)
- Uses `python:3.10-slim`
- Copies the scraped JSON
- Runs a Flask server to serve it over HTTP


ğŸ“ How to Use

ğŸ”¨ Build the Docker Image
docker build --build-arg SCRAPE_URL=https://techcrunch.com/startups/ -t puppeteer-flask-app .

â–¶ï¸ Run the Container
docker run -p 5000:5000 puppeteer-flask-app

ğŸŒ Access the Scraped Data
Visit: http://<your-ec2-public-ip>:5000/

ğŸ”„ Dynamic URL Support
You can scrape any site by passing a different SCRAPE_URL as a build argument : docker build --build-arg SCRAPE_URL=https://example.com -t puppeteer-flask-app .


ğŸ“¦ Requirements
Node.js
puppeteer
Python
flask

Install using:
# Node
cd scraper/
npm install

# Python
pip install -r requirements.txt

ğŸ“¸ Output
{
  "title": "Startup News â€“ TechCrunch",
  "heading": "Startups"
}

![Instance](https://github.com/user-attachments/assets/6e71f54e-710e-402e-aa7f-04acb0191372)
![Assignment](https://github.com/user-attachments/assets/03c9bd2a-a22c-4ecf-b225-abce3a43908b)

From-->http://54.161.227.172:5000/

ğŸ¤ Credits
This project was developed as part of a DevOps assignment, showcasing:
Real-world deployment on AWS EC2
Cross-language integration using Node.js + Python
Efficient and minimal Docker multi-stage builds

ğŸ§  Author
Soneeya
Connect on GitHub

